{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DB SIGN IN: ---\n",
      "reading .env files...\n",
      "successfully connected to:\t postgres\n",
      "available schemas:\t\t ecosystem_classifier, information_schema, public\n",
      "setting default schema to:\t ecosystem_classifier\n",
      "tables in default schema:\t radiance_2020, ndvi_2020, earthdata_1980, meteostat_2017, us_rules, meteostat_2010, meteostat_2012, meteostat_2013, meteostat_2014, meteostat_2018, meteostat_2000, elevation, us_gaz, earthdata_1990, earthdata_1995, us_lex, meteostat_2015, earthdata_2011, earthdata_2012, meteostat_1990, meteostat_2011, meteostat_stations, earthdata_1970, earthdata_2019, radiance_2017, radiance_2018, radiance_2019, radiance_2021, earthdata_2000, earthdata_2005, earthdata_2010, earthdata_2013, meteostat_2016, spatial_ref_sys, app_contact_messages, earthdata_2014, meteostat_2019, meteostat_2020, meteostat_2021, earthdata_2015, earthdata_2016, earthdata_2017, earthdata_2018, meteostat_2005, radiance_2012, radiance_2013, radiance_2014, radiance_2015, radiance_2016, radiance_2022, radiance_2023, meteostat_1995, earthdata_1960, earthdata_2021, earthdata_2022, earthdata_2023, earthdata_2020, earthdata_1948, earthdata_1950\n",
      "lat_min:\t 48.815573\n",
      "lat_max:\t 48.902145\n",
      "lon_min:\t 2.224199\n",
      "lon_max:\t 2.469921\n",
      "years:\t [2020]\n",
      ">>> Fitting tables: elevation, radiance_2020, ndvi_2020, meteostat_2020, earthdata_2020\n",
      "\n",
      "--- CHECKING TABLES: ---\n",
      "KEPT:\t\televation\n",
      "KEPT:\t\tradiance_2020\n",
      "KEPT:\t\tndvi_2020\n",
      "DISCARDED:\tmeteostat_2020 >>> does not feature 'lon/longitude' and 'lat/latitude' as columns\n",
      "KEPT:\t\tearthdata_2020\n",
      "\n",
      "--- FETCHING DATA: ---\n",
      ">>> SUCCESS: elevation data fetched\n",
      ">>> SUCCESS: radiance_2020 data fetched\n",
      ">>> SUCCESS: ndvi_2020 data fetched\n",
      ">>> SUCCESS: earthdata_2020 data fetched\n"
     ]
    }
   ],
   "source": [
    "from fetch_data import fetch_data_from_postgres\n",
    "#Merge data\n",
    "mvariables = {\n",
    "    \"ecosystem\" = \"Urban-City\"\n",
    "    \"lat_min\": 48.815573,\n",
    "    \"lat_max\": 48.902145,\n",
    "    \"lon_min\": 2.224199,\n",
    "    \"lon_max\": 2.469921,\n",
    "    \"years\": [2020]\n",
    "}\n",
    "\n",
    "json_outputs = fetch_data_from_postgres(variables=mvariables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged DataFrame:\n",
      "      lat    lon  elevation   radiance      ndvi  Swnet_min  Swnet_max  \\\n",
      "0  48.875  2.375       78.0  50.000786  0.394561  23.804476  204.75125   \n",
      "1  48.875  2.375       78.0  50.000788  0.394561  23.804476  204.75125   \n",
      "\n",
      "   Swnet_avg  Lwnet_min  Lwnet_max  ...  Qair_avg  Psurf_min   Psurf_max  \\\n",
      "0  114.74509 -82.530136   -34.4757  ...  0.006318   99721.39  101450.805   \n",
      "1  114.74509 -82.530136   -34.4757  ...  0.006318   99721.39  101450.805   \n",
      "\n",
      "   Psurf_avg  SWdown_min  SWdown_max  SWdown_avg  LWdown_min  LWdown_max  \\\n",
      "0  100724.99   26.911814   242.07588   133.78767   294.61588   369.89417   \n",
      "1  100724.99   26.911814   242.07588   133.78767   294.61588   369.89417   \n",
      "\n",
      "   LWdown_avg  \n",
      "0   325.08878  \n",
      "1   325.08878  \n",
      "\n",
      "[2 rows x 113 columns]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty list to store the DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop over each table in json_outputs\n",
    "for key, data in json_outputs.items():\n",
    "    # Parse JSON string if necessary\n",
    "    if isinstance(data, str):\n",
    "        try:\n",
    "            parsed_data = json.loads(data)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON for table '{key}': {e}\")\n",
    "            continue  # Skip this table if JSON parsing fails\n",
    "    else:\n",
    "        parsed_data = data\n",
    "\n",
    "    # Convert parsed data to a DataFrame\n",
    "    try:\n",
    "        df = pd.DataFrame(parsed_data)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error creating DataFrame for table '{key}': {e}\")\n",
    "        continue  # Skip this table if DataFrame creation fails\n",
    "\n",
    "    # Standardize column names to 'lat' and 'lon' for merging\n",
    "    if 'latitude' in df.columns and 'longitude' in df.columns:\n",
    "        df.rename(columns={'latitude': 'lat', 'longitude': 'lon'}, inplace=True)\n",
    "    elif 'lat' not in df.columns or 'lon' not in df.columns:\n",
    "        print(f\"Warning: Table '{key}' is missing required 'lat'/'lon' or 'latitude'/'longitude' columns.\")\n",
    "        continue  # Skip tables without valid latitude/longitude columns\n",
    "\n",
    "    # Append the DataFrame to the list\n",
    "    dfs.append(df)\n",
    "\n",
    "# Merge all DataFrames on 'lat' and 'lon' if there are valid DataFrames\n",
    "if dfs:\n",
    "    merged_df = dfs[0]\n",
    "    for df in dfs[1:]:\n",
    "        try:\n",
    "            merged_df = merged_df.merge(df, on=['lat', 'lon'], how='outer')\n",
    "        except KeyError as e:\n",
    "            print(f\"Error merging table due to missing 'lat'/'lon' columns: {e}\")\n",
    "            continue  # Skip merging if 'lat'/'lon' columns are missing\n",
    "\n",
    "    # Display the merged DataFrame\n",
    "    print(\"\\nMerged DataFrame:\")\n",
    "    print(merged_df.head(10))\n",
    "else:\n",
    "    print(\"No valid tables with latitude and longitude data were found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"ecosystem\"] = \"Urban-City\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
